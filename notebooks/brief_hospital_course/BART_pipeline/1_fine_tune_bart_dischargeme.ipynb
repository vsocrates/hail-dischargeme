{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "version = \"v1\"\n",
    "\n",
    "inputcol = \"bhc_preceding_text\"\n",
    "outputcol = \"brief_hospital_course\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8VR8kd4ipPN"
   },
   "source": [
    "# Fine-tuning BART for DischargeMe Brief Hospital Course Task\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUn2OqI9oPQb"
   },
   "source": [
    "## Setup\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rimUDCQGoTAJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import datasets\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "from tabulate import tabulate\n",
    "import nltk\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_functions import create_pt_prompt_per_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import data_injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn this on if you are running this not as an interactive notebook\n",
    "# datasets.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8zpflBQbzrvC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvimig-socrates\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "WANDB_INTEGRATION = True\n",
    "if WANDB_INTEGRATION:\n",
    "    import wandb\n",
    "\n",
    "    wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\", flush=True)\n",
    "\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\", flush=True)\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\", flush=True)\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aX-q_O-hoe3g"
   },
   "source": [
    "## Model and tokenizer\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb21WY-9mavn"
   },
   "source": [
    "Download model and tokenizer. Use default parameters or try custom values (see [HF Bart configuration](https://huggingface.co/transformers/_modules/transformers/configuration_bart.html) and [Fairseq Bart](https://github.com/pytorch/fairseq/tree/master/examples/bart))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320,
     "referenced_widgets": [
      "177dd46c6d5444aca5f500a9c9a8360c",
      "d8eb6df708df47bcaa680c45389f9789",
      "905192b1adad4ee298f82af962f67592",
      "d7834d5eecf9412391c7492f37e8e3ee",
      "ccbbe4c9daf043398c7029c926666275",
      "e9bf4b882c2041c584a4b0eb22e7fa70",
      "99f0d622b7e4430b85eccbfd8ddb00b3",
      "b4e2344137864b8ebd6ad78437c3a19a",
      "7cf993132faa4d89a64fd3eca312cdbc",
      "fbf907eddfe24e9399f10ea6d89f8f7d",
      "759aaa8b51b04df4b0287e0f76d9c20b",
      "6b1a1421e6e64fb6906f3e9a6aed5f21",
      "7efd4ea0ea5347399ed0b621dde70079",
      "965d92fa10254517b62c352d64dbde4d",
      "02ce7e45725d4ea8bb9e92e510ce461d",
      "4be0831bc19149919ce1d88a15740088",
      "6bce83a3cef143b6a111acdf64da0c4e",
      "b95c2cdea4bc40b08a05713e533e3aa9",
      "ba3fda5f01a1472884f3f9d0b0fc108d",
      "eaca0e42cbe04191be4cfc9fb50c1e1c",
      "32f7cae84a444897a2b4c0392bd9116f",
      "60d92abae8cd45fc9c33e62d441419a9",
      "7a0f47ee32c747388c52d9d18b43bf1c",
      "67f9afc232a04ffca994891d8aed9912",
      "a83ef7bd2dd440b99a5e9e0b509cfa3d",
      "ff705e5b53874c4085ce820e2e45fbef",
      "59c23e3de2554a72b405f947ea4dbdb3",
      "14aaadb3a50e46d0b4f05e6d0750696c",
      "70ccbe5adf3f48b1941ec90daa146989",
      "4ab611bbbc9c41588f02fbc3d879d6b9",
      "48a6682d09984cffa3a608a22dec4305",
      "d56a6f544c4942d48cd912b39d739619",
      "9033abd90902440db83b521af2362607",
      "620f66af1b874233b13b07b987bf5d5c",
      "de232831629e4de19886353c1c7dd639",
      "9b91df4680264521a9ce63306a5914fe",
      "2eab5b3f9aed410892d083b09d6da827",
      "a51df7c4e4bc43579173d14c203b71a8",
      "cbc1850d082e4d9fbb05c5b07026e0e2",
      "45d6fd520cec4b6ab4f385efea2393d1",
      "1ed29c61bb7240aebbd0fbda10a8fd1c",
      "be8f53768dcd466e9716a5fa36eb0b64",
      "fb58dc38229148fa9937dde37c923e24",
      "c6e527cc8c144b4db881b469f34be746",
      "061238de11e44920857de4521e98a51b",
      "67227a5963184d3ca75fa0aafb8ca072",
      "77b798c81e154102a71ac0a519bbe8a9",
      "8dcdd0dc6063416eb90800ea3046070c"
     ]
    },
    "editable": true,
    "id": "7vMhyyIPobyx",
    "outputId": "e28badd9-654b-475b-9ac0-a12b35ccdc2e",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"GanjinZero/biobart-large\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set model parameters or use the default\n",
    "# print(model.config)\n",
    "\n",
    "# tokenization\n",
    "encoder_max_length = 1024\n",
    "decoder_max_length = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwtSPRJgomBS"
   },
   "source": [
    "## Data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 319 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle(\"/gpfs/gibbs/project/rtaylor/shared/DischargeMe/public/train/discharge_target_with_preceding_text+structured_data.pickle\")\n",
    "valid_data = pd.read_pickle(\"/gpfs/gibbs/project/rtaylor/shared/DischargeMe/public/valid/discharge_target_with_preceding_text+structured_data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    68785.000000\n",
       "mean       327.462397\n",
       "std        236.807308\n",
       "min         10.000000\n",
       "25%        163.000000\n",
       "50%        281.000000\n",
       "75%        440.000000\n",
       "max       3435.000000\n",
       "Name: brief_hospital_course_word_count, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['brief_hospital_course_word_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_data[['hadm_id', inputcol, outputcol]], split=\"train\")\n",
    "valid_ds = Dataset.from_pandas(valid_data[['hadm_id', inputcol, outputcol]], split=\"valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjGvlbT6XBe6"
   },
   "source": [
    "### Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BD7uaok9474K"
   },
   "source": [
    "**Format and split into train and validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "8b43a79aaaf44bb4ae497911ec1cb069",
      "fff5dd9c027d4e0ca53102bb59289d64",
      "b28730387e29480fa43743dfbc6ba7a5",
      "d5ab7ba210954b4d8fd5e175ab78c636",
      "4fa1015ca37848088ab1c66488edfd20",
      "642a892a1999461ab4a35975b23fe330",
      "df9c9948711a4bb6b5c6864095fc9a9f",
      "e284a90cb37345eea8f2ecdd5ef65940",
      "db16d22c18c440b0be96b99a2b144819",
      "6d0028934af84743b9de85ed7172b931",
      "82e9ca2b98fc40c3a07bbfa62055b197",
      "bd3a31515c02447e9e5574d420e781a8",
      "b5c0b01cb2114d5c93f800997b663f87",
      "a5fa1ead5ecb4d688969746b489c741d",
      "c91957e3842c4af7baf3403b4554b2bc",
      "4dc306fd47e44b5ca5e14da342362eba"
     ]
    },
    "id": "M3TeTKzQ49CO",
    "outputId": "fdcc5de9-a4da-4baf-c4f1-fe93b42c77b9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38b2b09dff34f3facee3b47b47cd356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/68785 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4c136dea8a4034ac0367f92499a190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14719 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def flatten(example):\n",
    "    return {\n",
    "        \"document\": example[inputcol],\n",
    "        \"summary\": example[outputcol],\n",
    "    }\n",
    "\n",
    "\n",
    "def list2samples(example):\n",
    "    documents = []\n",
    "    summaries = []\n",
    "    for sample in zip(example[\"document\"], example[\"summary\"]):\n",
    "        if len(sample[0]) > 0:\n",
    "            documents += sample[0]\n",
    "            summaries += sample[1]\n",
    "    return {\"document\": documents, \"summary\": summaries}\n",
    "\n",
    "\n",
    "train_dataset_txt = train_ds.map(flatten, remove_columns=['hadm_id', inputcol, outputcol])\n",
    "valid_dataset_txt = valid_ds.map(flatten, remove_columns=['hadm_id', inputcol, outputcol])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pbe750YpMfD"
   },
   "source": [
    "**Preprocess and tokenize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "d746734a9c51418c864801d55a09638b",
      "ce0b55032013487b912bb982971f126d",
      "3cb71c39c7d04451b89acdec2efbe964",
      "c98e43401f4b43e49d6625cefc9467de",
      "1e2df782a99b4273a80334f1d44780ac",
      "e2cceac1ede3433f887a716ad177a160",
      "0eef45d80219425e982d0ea0a78344f9",
      "c979275e29b544d0b8e982a049bf8e22",
      "75678a6b33d54fec8500e96728966970",
      "5ed5ea35b4bc4d10afee05becdc467d7",
      "f35b5e590d6a4fff9c1005c99201ffbf",
      "7b6c91323d4f4c1e9e0647429940fd53",
      "54513cf682ce408c88f856803e390bea",
      "a9e45262444746138b274573415c171d",
      "e490b67d80884bdbbaaf97e2ce5fb0ad",
      "9021f9227b8948bba7dfeabba65c9e55"
     ]
    },
    "editable": true,
    "id": "PyksYNwxA4OM",
    "outputId": "dc317686-0868-4fe5-d7ee-bbb84de6836f",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d093669601f4286a307a2bd7bf54db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/68785 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb98df63392408191b8a5f32fd32766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14719 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n",
    "    source, target = batch[\"document\"], batch[\"summary\"]\n",
    "    source_tokenized = tokenizer(\n",
    "        source, padding=\"max_length\", truncation=True, max_length=max_source_length\n",
    "    )\n",
    "    target_tokenized = tokenizer(\n",
    "        target, padding=\"max_length\", truncation=True, max_length=max_target_length\n",
    "    )\n",
    "\n",
    "    batch = {k: v for k, v in source_tokenized.items()}\n",
    "    # Ignore padding in the loss\n",
    "    batch[\"labels\"] = [\n",
    "        [-100 if token == tokenizer.pad_token_id else token for token in l]\n",
    "        for l in target_tokenized[\"input_ids\"]\n",
    "    ]\n",
    "    return batch\n",
    "\n",
    "\n",
    "train_data = train_dataset_txt.map(\n",
    "    lambda batch: batch_tokenize_preprocess(\n",
    "        batch, tokenizer, encoder_max_length, decoder_max_length\n",
    "    ),\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset_txt.column_names,\n",
    ")\n",
    "\n",
    "validation_data = valid_dataset_txt.map(\n",
    "    lambda batch: batch_tokenize_preprocess(\n",
    "        batch, tokenizer, encoder_max_length, decoder_max_length\n",
    "    ),\n",
    "    batched=True,\n",
    "    remove_columns=valid_dataset_txt.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all the above preprocessing to file so we don't have to read it in again\n",
    "\n",
    "# train_data.save_to_disk(\"/gpfs/gibbs/project/rtaylor/shared/DischargeMe/public/train/discharge_target_with_preceding_text_BioBART_data.hf\")\n",
    "# validation_data.save_to_disk(\"/gpfs/gibbs/project/rtaylor/shared/DischargeMe/public/valid/discharge_target_with_preceding_text_BioBART_data.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment this out if you haven't generated the tokenized data above. \n",
    "\n",
    "from datasets import load_from_disk\n",
    "train_data = load_from_disk(\"/gpfs/gibbs/project/rtaylor/shared/DischargeMe/public/train/discharge_target_with_preceding_text_BioBART_data.hf\")\n",
    "validation_data = load_from_disk(\"/gpfs/gibbs/project/rtaylor/shared/DischargeMe/public/valid/discharge_target_with_preceding_text_BioBART_data.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After processing datasets\n",
      "GPU memory occupied: 319 MB.\n"
     ]
    }
   ],
   "source": [
    "print(\"After processing datasets\", flush=True)\n",
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(test_samples, model):\n",
    "    inputs = tokenizer(\n",
    "        test_samples[\"document\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=encoder_max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    return inputs\n",
    "    input_ids = inputs.input_ids.to(model.device)\n",
    "    attention_mask = inputs.attention_mask.to(model.device)\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask, num_beams=4, min_length=200, max_length=1500, early_stopping=True)\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return outputs, output_str\n",
    "\n",
    "\n",
    "model_before_tuning = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "h7ViBmMopWfb",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EfTztMPv2vG"
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68,
     "referenced_widgets": [
      "1eb628ce400d48d39e77b1950e928025",
      "fcd19732a34c47b5b2ca5a643f2d085d",
      "6086a4b108b74f219fff01890d22cd20",
      "1f743d0d7b154cafb344ed0c015f6910",
      "48397443928d452285fa439aaa6f369a",
      "4c8584515ed14f92b06136d6bb21629d",
      "b444d0d09e1b46b3a6382e90aa9c9512",
      "eeb32fd422934ecb8406f4b49e924de8"
     ]
    },
    "editable": true,
    "id": "rpNCGl2sYl2p",
    "outputId": "228587e5-ffbc-4bf8-b9d2-6f63e3d50420",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2051767/4242988070.py:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = datasets.load_metric(\"rouge\")\n",
      "/home/vs428/.conda/envs/peft_finetune_env/lib/python3.12/site-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba2ec18674f41b2adce39779da9246c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Borrowed from https://github.com/huggingface/transformers/blob/master/examples/seq2seq/run_summarization.py\n",
    "\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "metric = datasets.load_metric(\"rouge\")\n",
    "\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    # Extract a few results from ROUGE\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "\n",
    "    prediction_lens = [\n",
    "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
    "    ]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8O1EeUi-pbPA"
   },
   "source": [
    "### Training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 2\n",
    "# train_size = train_data.num_rows\n",
    "# train_batch_size = 8\n",
    "# ga_steps = 1\n",
    "# virtual_batch_size = train_batch_size * ga_steps   # \"invented name\" => 256\n",
    "# per_epoch_steps = int(train_size / virtual_batch_size + 0.5) # round => 121\n",
    "# total_steps = epochs * per_epoch_steps # => 605"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true,
    "id": "6R9d7ELIpX9F",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vs428/.conda/envs/peft_finetune_env/lib/python3.12/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Using auto half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"bart-dischargeme-results_{version}\",\n",
    "    num_train_epochs=2, \n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=2,\n",
    "    # learning_rate=3e-05,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.1,\n",
    "    label_smoothing_factor=0.1,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir=f\"bart-dischargeme-logs_{version}\",\n",
    "    logging_steps=5,\n",
    "    save_total_limit=2,\n",
    "\n",
    "    # additional args we added\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=250,\n",
    "    save_steps=500,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    "    metric_for_best_model='eval_loss',\n",
    "    load_best_model_at_end=True,\n",
    "    greater_is_better=False,\n",
    "    disable_tqdm=True,\n",
    "    log_level=\"info\",\n",
    "    logging_first_step=True,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_data,\n",
    "    # we only evaluate on a set of 2000 because it faster to measure progress and select best model\n",
    "    eval_dataset=validation_data.shuffle(seed=42).select(range(2000)),\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== After setting up trainer and args ==============\n",
      "GPU memory occupied: 2139 MB.\n"
     ]
    }
   ],
   "source": [
    "print(\"============== After setting up trainer and args ==============\", flush=True)\n",
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qzcsz3gKplPO"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rpg2a0mfoD-l"
   },
   "source": [
    "Wandb integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true,
    "id": "tdaVPp9doF1c",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vast/palmer/home.mccleary/vs428/Documents/DischargeMe/hail-dischargeme/notebooks/brief_hospital_course/BART_pipeline/wandb/run-20240430_145518-090ga0d7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vimig-socrates/bart-dischargeme/runs/090ga0d7' target=\"_blank\">stellar-surf-19</a></strong> to <a href='https://wandb.ai/vimig-socrates/bart-dischargeme' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vimig-socrates/bart-dischargeme' target=\"_blank\">https://wandb.ai/vimig-socrates/bart-dischargeme</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vimig-socrates/bart-dischargeme/runs/090ga0d7' target=\"_blank\">https://wandb.ai/vimig-socrates/bart-dischargeme/runs/090ga0d7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if WANDB_INTEGRATION:\n",
    "    wandb_run = wandb.init(\n",
    "        project=\"bart-dischargeme\",\n",
    "        config={\n",
    "            \"per_device_train_batch_size\": training_args.per_device_train_batch_size,\n",
    "            \"learning_rate\": training_args.learning_rate,\n",
    "            \"dataset\": \"dischargeme preceding_text_only\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H%M%S\")\n",
    "    wandb_run.name = \"run_\" + current_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEtd_a7TPpkd"
   },
   "source": [
    "Evaluate before fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Before trainer.evaluate() pretrain ==============\n",
      "GPU memory occupied: 2139 MB.\n"
     ]
    }
   ],
   "source": [
    "print(\"============== Before trainer.evaluate() pretrain ==============\", flush=True)\n",
    "print_gpu_utilization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "editable": true,
    "id": "5yveDiz7pm3i",
    "outputId": "e0793d3b-389c-40a4-ea4a-c0d4c15a8017",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 2\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "/home/vs428/.conda/envs/peft_finetune_env/lib/python3.12/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.941129684448242, 'eval_rouge1': 0.2535, 'eval_rouge2': 0.0145, 'eval_rougeL': 0.2245, 'eval_rougeLsum': 0.2506, 'eval_gen_len': 20.0, 'eval_runtime': 426.5652, 'eval_samples_per_second': 4.689, 'eval_steps_per_second': 2.344}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 7.941129684448242,\n",
       " 'eval_rouge1': 0.2535,\n",
       " 'eval_rouge2': 0.0145,\n",
       " 'eval_rougeL': 0.2245,\n",
       " 'eval_rougeLsum': 0.2506,\n",
       " 'eval_gen_len': 20.0,\n",
       " 'eval_runtime': 426.5652,\n",
       " 'eval_samples_per_second': 4.689,\n",
       " 'eval_steps_per_second': 2.344}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run an initial full validation dataset evaluation to get a baseline\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== After trainer.evaluate() pretrain ==============\n",
      "GPU memory occupied: 5311 MB.\n"
     ]
    }
   ],
   "source": [
    "print(\"============== After trainer.evaluate() pretrain ==============\", flush=True)\n",
    "print_gpu_utilization()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "nkRb7hvgPrf2",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 847
    },
    "editable": true,
    "id": "qYcYcbkr7ZZD",
    "outputId": "84cf21c8-5a40-4f44-82ed-55a83c7d5100",
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 68,785\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17,198\n",
      "  Number of trainable parameters = 406,291,456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 8.3042, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.0}\n",
      "{'loss': 8.3542, 'grad_norm': 39.05048751831055, 'learning_rate': 2.0000000000000002e-07, 'epoch': 0.0}\n",
      "{'loss': 8.3989, 'grad_norm': 48.65020751953125, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.0}\n",
      "{'loss': 7.9502, 'grad_norm': 26.361770629882812, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.0}\n",
      "{'loss': 7.5405, 'grad_norm': 20.091793060302734, 'learning_rate': 1.7000000000000002e-06, 'epoch': 0.0}\n",
      "{'loss': 6.9417, 'grad_norm': 14.027737617492676, 'learning_rate': 2.2e-06, 'epoch': 0.0}\n",
      "{'loss': 6.2932, 'grad_norm': 8.123832702636719, 'learning_rate': 2.7e-06, 'epoch': 0.0}\n",
      "{'loss': 5.8968, 'grad_norm': 6.940796375274658, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.0}\n",
      "{'loss': 5.8289, 'grad_norm': 6.318179130554199, 'learning_rate': 3.7e-06, 'epoch': 0.0}\n",
      "{'loss': 5.5069, 'grad_norm': 3.9666635990142822, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.01}\n",
      "{'loss': 5.3415, 'grad_norm': 4.445992946624756, 'learning_rate': 4.7e-06, 'epoch': 0.01}\n",
      "{'loss': 5.1275, 'grad_norm': 3.6453921794891357, 'learning_rate': 5.2e-06, 'epoch': 0.01}\n",
      "{'loss': 5.056, 'grad_norm': 3.3048317432403564, 'learning_rate': 5.7000000000000005e-06, 'epoch': 0.01}\n",
      "{'loss': 4.9973, 'grad_norm': 2.8683106899261475, 'learning_rate': 6.2e-06, 'epoch': 0.01}\n",
      "{'loss': 4.8653, 'grad_norm': 3.2895026206970215, 'learning_rate': 6.700000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 4.8108, 'grad_norm': 2.480428457260132, 'learning_rate': 7.2e-06, 'epoch': 0.01}\n",
      "{'loss': 4.7997, 'grad_norm': 3.1017327308654785, 'learning_rate': 7.7e-06, 'epoch': 0.01}\n",
      "{'loss': 4.5821, 'grad_norm': 2.56276798248291, 'learning_rate': 8.200000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 4.6447, 'grad_norm': 2.7310097217559814, 'learning_rate': 8.7e-06, 'epoch': 0.01}\n",
      "{'loss': 4.5421, 'grad_norm': 2.3551025390625, 'learning_rate': 9.2e-06, 'epoch': 0.01}\n",
      "{'loss': 4.3884, 'grad_norm': 2.877254009246826, 'learning_rate': 9.7e-06, 'epoch': 0.01}\n",
      "{'loss': 4.5019, 'grad_norm': 2.4399466514587402, 'learning_rate': 1.02e-05, 'epoch': 0.01}\n",
      "{'loss': 4.4746, 'grad_norm': 2.6289825439453125, 'learning_rate': 1.0700000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 4.452, 'grad_norm': 2.3111090660095215, 'learning_rate': 1.1200000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 4.4782, 'grad_norm': 2.373288154602051, 'learning_rate': 1.1700000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 4.4215, 'grad_norm': 3.002761125564575, 'learning_rate': 1.22e-05, 'epoch': 0.01}\n",
      "{'loss': 4.4732, 'grad_norm': 2.694580078125, 'learning_rate': 1.27e-05, 'epoch': 0.02}\n",
      "{'loss': 4.2795, 'grad_norm': 2.4106287956237793, 'learning_rate': 1.32e-05, 'epoch': 0.02}\n",
      "{'loss': 4.2736, 'grad_norm': 2.5115973949432373, 'learning_rate': 1.3700000000000001e-05, 'epoch': 0.02}\n",
      "{'loss': 4.3547, 'grad_norm': 2.180227279663086, 'learning_rate': 1.42e-05, 'epoch': 0.02}\n",
      "{'loss': 4.2387, 'grad_norm': 2.6090455055236816, 'learning_rate': 1.47e-05, 'epoch': 0.02}\n",
      "{'loss': 4.2935, 'grad_norm': 2.2664923667907715, 'learning_rate': 1.52e-05, 'epoch': 0.02}\n",
      "{'loss': 4.1472, 'grad_norm': 2.7870428562164307, 'learning_rate': 1.5700000000000002e-05, 'epoch': 0.02}\n",
      "{'loss': 4.233, 'grad_norm': 2.4408648014068604, 'learning_rate': 1.62e-05, 'epoch': 0.02}\n",
      "{'loss': 4.1806, 'grad_norm': 2.5164828300476074, 'learning_rate': 1.6700000000000003e-05, 'epoch': 0.02}\n",
      "{'loss': 4.2541, 'grad_norm': 2.0730183124542236, 'learning_rate': 1.7199999999999998e-05, 'epoch': 0.02}\n",
      "{'loss': 4.2686, 'grad_norm': 2.8254690170288086, 'learning_rate': 1.77e-05, 'epoch': 0.02}\n",
      "{'loss': 4.0523, 'grad_norm': 2.6005117893218994, 'learning_rate': 1.8200000000000002e-05, 'epoch': 0.02}\n",
      "{'loss': 4.1967, 'grad_norm': 2.0093019008636475, 'learning_rate': 1.87e-05, 'epoch': 0.02}\n",
      "{'loss': 4.1267, 'grad_norm': 2.1352386474609375, 'learning_rate': 1.9200000000000003e-05, 'epoch': 0.02}\n",
      "{'loss': 4.1625, 'grad_norm': 2.5932321548461914, 'learning_rate': 1.97e-05, 'epoch': 0.02}\n",
      "{'loss': 4.0652, 'grad_norm': 2.3732452392578125, 'learning_rate': 2.0200000000000003e-05, 'epoch': 0.02}\n",
      "{'loss': 4.1219, 'grad_norm': 2.881549596786499, 'learning_rate': 2.07e-05, 'epoch': 0.02}\n",
      "{'loss': 4.1092, 'grad_norm': 2.4454057216644287, 'learning_rate': 2.12e-05, 'epoch': 0.03}\n",
      "{'loss': 4.0903, 'grad_norm': 2.4065825939178467, 'learning_rate': 2.1700000000000002e-05, 'epoch': 0.03}\n",
      "{'loss': 4.1165, 'grad_norm': 1.948296308517456, 'learning_rate': 2.22e-05, 'epoch': 0.03}\n",
      "{'loss': 3.9746, 'grad_norm': 2.26837158203125, 'learning_rate': 2.2700000000000003e-05, 'epoch': 0.03}\n",
      "{'loss': 4.0332, 'grad_norm': 2.070631265640259, 'learning_rate': 2.32e-05, 'epoch': 0.03}\n",
      "{'loss': 3.9695, 'grad_norm': 2.019192934036255, 'learning_rate': 2.37e-05, 'epoch': 0.03}\n",
      "{'loss': 3.94, 'grad_norm': 2.029762029647827, 'learning_rate': 2.4200000000000002e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0782, 'grad_norm': 2.0047314167022705, 'learning_rate': 2.47e-05, 'epoch': 0.03}\n",
      "{'eval_loss': 3.7908928394317627, 'eval_rouge1': 7.5955, 'eval_rouge2': 4.5109, 'eval_rougeL': 6.9906, 'eval_rougeLsum': 7.4926, 'eval_gen_len': 20.0, 'eval_runtime': 426.9903, 'eval_samples_per_second': 4.684, 'eval_steps_per_second': 2.342, 'epoch': 0.03}\n",
      "{'loss': 3.9421, 'grad_norm': 1.8848192691802979, 'learning_rate': 2.5200000000000003e-05, 'epoch': 0.03}\n",
      "{'loss': 3.9671, 'grad_norm': 2.4494495391845703, 'learning_rate': 2.57e-05, 'epoch': 0.03}\n",
      "{'loss': 3.8797, 'grad_norm': 2.3967435359954834, 'learning_rate': 2.6200000000000003e-05, 'epoch': 0.03}\n",
      "{'loss': 4.034, 'grad_norm': 2.2060980796813965, 'learning_rate': 2.6700000000000002e-05, 'epoch': 0.03}\n",
      "{'loss': 3.9222, 'grad_norm': 1.9037469625473022, 'learning_rate': 2.7200000000000004e-05, 'epoch': 0.03}\n",
      "{'loss': 3.9342, 'grad_norm': 1.8078581094741821, 'learning_rate': 2.7700000000000002e-05, 'epoch': 0.03}\n",
      "{'loss': 3.8937, 'grad_norm': 2.477729320526123, 'learning_rate': 2.8199999999999998e-05, 'epoch': 0.03}\n",
      "{'loss': 4.0348, 'grad_norm': 2.05203914642334, 'learning_rate': 2.87e-05, 'epoch': 0.03}\n",
      "{'loss': 3.935, 'grad_norm': 2.4889495372772217, 'learning_rate': 2.9199999999999998e-05, 'epoch': 0.03}\n",
      "{'loss': 3.9642, 'grad_norm': 1.9789679050445557, 'learning_rate': 2.97e-05, 'epoch': 0.03}\n",
      "{'loss': 3.8325, 'grad_norm': 2.57680606842041, 'learning_rate': 3.02e-05, 'epoch': 0.04}\n",
      "{'loss': 3.88, 'grad_norm': 2.36624813079834, 'learning_rate': 3.07e-05, 'epoch': 0.04}\n",
      "{'loss': 3.931, 'grad_norm': 2.2318506240844727, 'learning_rate': 3.12e-05, 'epoch': 0.04}\n",
      "{'loss': 3.8556, 'grad_norm': 1.797717809677124, 'learning_rate': 3.1700000000000005e-05, 'epoch': 0.04}\n",
      "{'loss': 3.7636, 'grad_norm': 2.021148443222046, 'learning_rate': 3.2200000000000003e-05, 'epoch': 0.04}\n",
      "{'loss': 3.8621, 'grad_norm': 2.031567335128784, 'learning_rate': 3.27e-05, 'epoch': 0.04}\n",
      "{'loss': 3.9099, 'grad_norm': 2.155111074447632, 'learning_rate': 3.32e-05, 'epoch': 0.04}\n",
      "{'loss': 3.8345, 'grad_norm': 1.7438451051712036, 'learning_rate': 3.3700000000000006e-05, 'epoch': 0.04}\n",
      "{'loss': 3.9374, 'grad_norm': 1.8324224948883057, 'learning_rate': 3.4200000000000005e-05, 'epoch': 0.04}\n",
      "{'loss': 3.7939, 'grad_norm': 1.68795907497406, 'learning_rate': 3.4699999999999996e-05, 'epoch': 0.04}\n",
      "{'loss': 3.8238, 'grad_norm': 1.9409523010253906, 'learning_rate': 3.52e-05, 'epoch': 0.04}\n",
      "{'loss': 3.8779, 'grad_norm': 2.496534585952759, 'learning_rate': 3.57e-05, 'epoch': 0.04}\n",
      "{'loss': 3.8472, 'grad_norm': 1.9187283515930176, 'learning_rate': 3.62e-05, 'epoch': 0.04}\n",
      "{'loss': 3.7981, 'grad_norm': 2.3873040676116943, 'learning_rate': 3.6700000000000004e-05, 'epoch': 0.04}\n",
      "{'loss': 3.7702, 'grad_norm': 1.7489560842514038, 'learning_rate': 3.72e-05, 'epoch': 0.04}\n",
      "{'loss': 3.773, 'grad_norm': 1.8846945762634277, 'learning_rate': 3.77e-05, 'epoch': 0.04}\n",
      "{'loss': 3.7661, 'grad_norm': 1.8385907411575317, 'learning_rate': 3.82e-05, 'epoch': 0.04}\n",
      "{'loss': 3.6891, 'grad_norm': 1.8930089473724365, 'learning_rate': 3.8700000000000006e-05, 'epoch': 0.05}\n",
      "{'loss': 3.7141, 'grad_norm': 1.798061490058899, 'learning_rate': 3.9200000000000004e-05, 'epoch': 0.05}\n",
      "{'loss': 3.8633, 'grad_norm': 1.860897183418274, 'learning_rate': 3.97e-05, 'epoch': 0.05}\n",
      "{'loss': 3.841, 'grad_norm': 2.688725471496582, 'learning_rate': 4.02e-05, 'epoch': 0.05}\n",
      "{'loss': 3.8896, 'grad_norm': 2.2269365787506104, 'learning_rate': 4.07e-05, 'epoch': 0.05}\n",
      "{'loss': 3.7284, 'grad_norm': 1.9749102592468262, 'learning_rate': 4.12e-05, 'epoch': 0.05}\n",
      "{'loss': 3.7699, 'grad_norm': 2.483293294906616, 'learning_rate': 4.17e-05, 'epoch': 0.05}\n",
      "{'loss': 3.7713, 'grad_norm': 2.175720691680908, 'learning_rate': 4.22e-05, 'epoch': 0.05}\n",
      "{'loss': 3.7437, 'grad_norm': 2.533250570297241, 'learning_rate': 4.27e-05, 'epoch': 0.05}\n",
      "{'loss': 3.8332, 'grad_norm': 1.9871882200241089, 'learning_rate': 4.32e-05, 'epoch': 0.05}\n",
      "{'loss': 3.6663, 'grad_norm': 1.7704660892486572, 'learning_rate': 4.3700000000000005e-05, 'epoch': 0.05}\n",
      "{'loss': 3.7709, 'grad_norm': 1.7128336429595947, 'learning_rate': 4.4200000000000004e-05, 'epoch': 0.05}\n",
      "{'loss': 3.6405, 'grad_norm': 2.1570942401885986, 'learning_rate': 4.47e-05, 'epoch': 0.05}\n",
      "{'loss': 3.8728, 'grad_norm': 4.764730453491211, 'learning_rate': 4.52e-05, 'epoch': 0.05}\n",
      "{'loss': 3.7989, 'grad_norm': 1.7839397192001343, 'learning_rate': 4.5700000000000006e-05, 'epoch': 0.05}\n",
      "{'loss': 3.5526, 'grad_norm': 1.8264249563217163, 'learning_rate': 4.6200000000000005e-05, 'epoch': 0.05}\n",
      "{'loss': 3.6808, 'grad_norm': 1.6826339960098267, 'learning_rate': 4.6700000000000003e-05, 'epoch': 0.05}\n",
      "{'loss': 3.6876, 'grad_norm': 1.9408210515975952, 'learning_rate': 4.72e-05, 'epoch': 0.06}\n",
      "{'loss': 3.6976, 'grad_norm': 1.9933934211730957, 'learning_rate': 4.77e-05, 'epoch': 0.06}\n",
      "{'loss': 3.7302, 'grad_norm': 1.9423824548721313, 'learning_rate': 4.82e-05, 'epoch': 0.06}\n",
      "{'loss': 3.6544, 'grad_norm': 2.300173044204712, 'learning_rate': 4.87e-05, 'epoch': 0.06}\n",
      "{'loss': 3.8012, 'grad_norm': 1.7936913967132568, 'learning_rate': 4.92e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7515, 'grad_norm': 2.314866065979004, 'learning_rate': 4.97e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to bart-dischargeme-results_v1/tmp-checkpoint-500\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\n",
      "Configuration saved in bart-dischargeme-results_v1/tmp-checkpoint-500/config.json\n",
      "Configuration saved in bart-dischargeme-results_v1/tmp-checkpoint-500/generation_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.5171148777008057, 'eval_rouge1': 7.6906, 'eval_rouge2': 4.5627, 'eval_rougeL': 7.0861, 'eval_rougeLsum': 7.5985, 'eval_gen_len': 20.0, 'eval_runtime': 426.8672, 'eval_samples_per_second': 4.685, 'eval_steps_per_second': 2.343, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bart-dischargeme-results_v1/tmp-checkpoint-500/model.safetensors\n",
      "tokenizer config file saved in bart-dischargeme-results_v1/tmp-checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in bart-dischargeme-results_v1/tmp-checkpoint-500/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "#%%wandb\n",
    "# uncomment to display Wandb charts\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"============== After trainer.train() ==============\", flush=True)\n",
    "print_gpu_utilization()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3C-4SfOPssY"
   },
   "source": [
    "Evaluate after fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "editable": true,
    "id": "_-QyUtCRH9DO",
    "outputId": "0b5b5583-0ba1-462d-9645-37422a3333e2",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run an final full validation dataset evaluation to get the best metrics at the end\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b752706b4845420f939aae77bad05b8d",
      "3725321613124a9fb555bd4ef31035fd",
      "dd16f78c32f2412498419687cde38779",
      "d0e495d4dddb488799142d6a2550872b",
      "1a31a81cb51541b089a0b1e6df281963",
      "131ff7a29b1a4853a3cd840f78904a07",
      "e626643516fa4c3f87d72ee7406107cd",
      "62c757374f504b54bd911d333b349e2e"
     ]
    },
    "editable": true,
    "id": "ClRTrG2ETUm3",
    "outputId": "98c2c66a-09ec-4889-85e3-41c661623426",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if WANDB_INTEGRATION:\n",
    "    wandb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gSLVnGL9bol"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "hDwj24cfILS6",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Generate summaries from the fine-tuned model and compare them with those generated from the original, pre-trained one.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"/home/vs428/Documents/DischargeMe/hail-dischargeme/notebooks/brief_hospital_course/template_code/bart-dischargeme-results_v2/checkpoint-16500/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "NV64-XdA_rOM",
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_summary(test_samples, model):\n",
    "    inputs = tokenizer(\n",
    "        test_samples[\"document\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=encoder_max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = inputs.input_ids.to(model.device)\n",
    "    attention_mask = inputs.attention_mask.to(model.device)\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask, num_beams=4, min_length=200, max_length=1500, early_stopping=True)\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return outputs, output_str\n",
    "\n",
    "\n",
    "model_before_tuning = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_samples = valid_dataset_txt.select(range(3))\n",
    "x, summaries_before_tuning = generate_summary(test_samples, model_before_tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, summaries_after_tuning = generate_summary(test_samples, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D7IPtJLjCcmS",
    "outputId": "fa863bb8-8bb7-4988-f322-faab93b6d395"
   },
   "outputs": [],
   "source": [
    "# Get some example summaries\n",
    "print(\n",
    "    tabulate(\n",
    "        zip(\n",
    "            range(len(summaries_after_tuning)),\n",
    "            test_samples[\"summary\"],\n",
    "            summaries_after_tuning,\n",
    "        ),\n",
    "        headers=[\"Id\", \"Summary Gold\", \"Summary BART\"],\n",
    "    )\n",
    ")\n",
    "# print(\"\\nTarget summaries:\\n\")\n",
    "# print(\n",
    "#     tabulate(list(enumerate(test_samples[\"summary\"])), headers=[\"Id\", \"Target summary\"])\n",
    "# )\n",
    "# print(\"\\nSource documents:\\n\")\n",
    "# print(tabulate(list(enumerate(test_samples[\"document\"])), headers=[\"Id\", \"Document\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "fine_tune_bart_summarization_two_langs.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0005712792bf4e399e190ccd6f702914": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "012c22d66e3d4888bee815c86cfe3110": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0466ea46ae454816921b423807a2aec4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0474890381244c7f91db5e07b6286974": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_fa747db3ae5e49548b936c55d16e525d",
       "style": "IPY_MODEL_682746e45d03417ba8bf24bc9ee636d3"
      }
     },
     "06d73a2484e04fb6852217b3b980ce10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0a4e6d31dbd74a11829139eb35d6627c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0f0d5488be4d4af5920a976154aad5b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4aba3bf70dd04ef8a951cec03058907f",
       "style": "IPY_MODEL_56e3458b9c414cfc8651aec2deb8ed8f",
       "value": "Map: 100%"
      }
     },
     "1519ae7194184fdfa999e692c7a52ca6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "173774f70c8a4a29a75ee1834f35055a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "298f9d8c7a564b328b8140424ec41ebd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "2fb98df63392408191b8a5f32fd32766": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_fdcec9b4db554289870860096e8c5b46",
        "IPY_MODEL_7826ee1504b14ed0bb7979407080ccba",
        "IPY_MODEL_7ffd96cf895445c9b84dd62189670680"
       ],
       "layout": "IPY_MODEL_89911d48a31f48d5bd8c12a93952c8a6"
      }
     },
     "3182b279702746c9baf2072b6beaa597": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_58a725ddc2b6424ba1e0fa6e0ef483e5",
       "style": "IPY_MODEL_1519ae7194184fdfa999e692c7a52ca6",
       "value": " 5.65k/? [00:00&lt;00:00, 620kB/s]"
      }
     },
     "333727eac85645d789b4e013693bd4a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3a17efba3e824b7cb7416c7168944f8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_0466ea46ae454816921b423807a2aec4",
       "style": "IPY_MODEL_ee23e8873d2d48889c738dbbe866db9f",
       "value": "Map: 100%"
      }
     },
     "3a44cf9bd933449cb500d63f65590d92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_a63ae4bf2bb946db996c361cd44172bc",
       "max": 68785,
       "style": "IPY_MODEL_af08f72d80854b108f75b31515e9c446",
       "value": 68785
      }
     },
     "3c290d7a9b384894baffc8e56d502ea6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_c4859dcf69ad49deb7deb191f44077ff",
       "max": 68785,
       "style": "IPY_MODEL_5e3fafa706e741038019bd65b78a51a1",
       "value": 68785
      }
     },
     "3d093669601f4286a307a2bd7bf54db3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_3a17efba3e824b7cb7416c7168944f8b",
        "IPY_MODEL_3a44cf9bd933449cb500d63f65590d92",
        "IPY_MODEL_dc25cb47450b471fb3edde2416d50956"
       ],
       "layout": "IPY_MODEL_0a4e6d31dbd74a11829139eb35d6627c"
      }
     },
     "4326696eb3d14a01a3f16c7abff0f990": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "45117799d5a44f94a8af4a5db32b74ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_dadd7de408374997931e287e444a7947",
       "style": "IPY_MODEL_93b2159ff95b484a80920f62186c5e2e",
       "value": "Map: 100%"
      }
     },
     "4aba3bf70dd04ef8a951cec03058907f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "519ae8ae13d441f39a6aece65f99ab52": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "52c2bb74594b4abba1ad16de38eb3bbc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_e6be953a09f44f76aa25b70692c73524",
       "style": "IPY_MODEL_298f9d8c7a564b328b8140424ec41ebd"
      }
     },
     "56e3458b9c414cfc8651aec2deb8ed8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "576e4d175f8f4b9ca4cff73cd1761327": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_eb308df0213f4dd2a4f88eea096efc08",
       "max": 1,
       "style": "IPY_MODEL_173774f70c8a4a29a75ee1834f35055a"
      }
     },
     "58a725ddc2b6424ba1e0fa6e0ef483e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5e3fafa706e741038019bd65b78a51a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "625252b36f8548c0a7d37372fd0c303a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6523c257a27b4c00b72bdec8112fe51a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_52c2bb74594b4abba1ad16de38eb3bbc",
        "IPY_MODEL_576e4d175f8f4b9ca4cff73cd1761327"
       ],
       "layout": "IPY_MODEL_519ae8ae13d441f39a6aece65f99ab52"
      }
     },
     "6563b0722a674c958642fd7bd76ebda6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "65a201512f5e43b7894d35cb62add340": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_0474890381244c7f91db5e07b6286974",
        "IPY_MODEL_e8d5155d1e044d9fbc95e8faf524230c"
       ],
       "layout": "IPY_MODEL_625252b36f8548c0a7d37372fd0c303a"
      }
     },
     "682746e45d03417ba8bf24bc9ee636d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "7461f9feddf54985afbdc18ee29b1e27": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7826ee1504b14ed0bb7979407080ccba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_333727eac85645d789b4e013693bd4a4",
       "max": 14719,
       "style": "IPY_MODEL_e135a8de9cfa4c088ae2dbbf45667dc3",
       "value": 14719
      }
     },
     "7e8bcbe56ec64be39d62c4c8e4163712": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7ffd96cf895445c9b84dd62189670680": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ca38b102c7dd401ba5b21d3b0714603b",
       "style": "IPY_MODEL_d80b3bdb2f884758a991f1f322492294",
       "value": " 14719/14719 [02:17&lt;00:00, 107.48 examples/s]"
      }
     },
     "89911d48a31f48d5bd8c12a93952c8a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9269ae93a4954efa92ecf2d5ba983c6e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "93b2159ff95b484a80920f62186c5e2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "95c507c01fe843b081c55f315d904a52": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "98d13f78e14c4797b65fcacfa7ca480e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9d8c8f631c28465eb7539f3ba8c0428b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9f19406cf47744cea5cae54c550b84f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a4dddeb7bf5048eb93542c295a4c3155": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a63ae4bf2bb946db996c361cd44172bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a8ed2f09f5b9439b8ac3c1f4c263231f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_012c22d66e3d4888bee815c86cfe3110",
       "max": 2169,
       "style": "IPY_MODEL_bcad035c569e4c51aedcf1a4acd11943",
       "value": 2169
      }
     },
     "af08f72d80854b108f75b31515e9c446": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "bba2ec18674f41b2adce39779da9246c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f836bd2efe0646699d7311a0a188aa8d",
        "IPY_MODEL_a8ed2f09f5b9439b8ac3c1f4c263231f",
        "IPY_MODEL_3182b279702746c9baf2072b6beaa597"
       ],
       "layout": "IPY_MODEL_0005712792bf4e399e190ccd6f702914"
      }
     },
     "bcad035c569e4c51aedcf1a4acd11943": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c4859dcf69ad49deb7deb191f44077ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ca38b102c7dd401ba5b21d3b0714603b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d80b3bdb2f884758a991f1f322492294": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "da0152cf4aca4b248938c0032e9ea2ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "da8551287ac14e61a8d4b013d1708526": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dadd7de408374997931e287e444a7947": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dc25cb47450b471fb3edde2416d50956": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9269ae93a4954efa92ecf2d5ba983c6e",
       "style": "IPY_MODEL_7e8bcbe56ec64be39d62c4c8e4163712",
       "value": " 68785/68785 [06:00&lt;00:00, 191.40 examples/s]"
      }
     },
     "e12a7d2aaf39458eb2a95d41007016de": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e135a8de9cfa4c088ae2dbbf45667dc3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e38b2b09dff34f3facee3b47b47cd356": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_45117799d5a44f94a8af4a5db32b74ad",
        "IPY_MODEL_3c290d7a9b384894baffc8e56d502ea6",
        "IPY_MODEL_f820722e5fbb41ebbff7770ccb3fd0f6"
       ],
       "layout": "IPY_MODEL_9f19406cf47744cea5cae54c550b84f2"
      }
     },
     "e3d122412e0f419a993c146fc18aca97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_da8551287ac14e61a8d4b013d1708526",
       "max": 14719,
       "style": "IPY_MODEL_06d73a2484e04fb6852217b3b980ce10",
       "value": 14719
      }
     },
     "e509dd015da04b07a6a33d60a31d6d69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6563b0722a674c958642fd7bd76ebda6",
       "style": "IPY_MODEL_98d13f78e14c4797b65fcacfa7ca480e",
       "value": " 14719/14719 [00:00&lt;00:00, 16054.19 examples/s]"
      }
     },
     "e6be953a09f44f76aa25b70692c73524": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e8d5155d1e044d9fbc95e8faf524230c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_ff2de936e84b4913b9ac257218c3d804",
       "max": 1,
       "style": "IPY_MODEL_4326696eb3d14a01a3f16c7abff0f990"
      }
     },
     "eb308df0213f4dd2a4f88eea096efc08": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "eb4c136dea8a4034ac0367f92499a190": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_0f0d5488be4d4af5920a976154aad5b1",
        "IPY_MODEL_e3d122412e0f419a993c146fc18aca97",
        "IPY_MODEL_e509dd015da04b07a6a33d60a31d6d69"
       ],
       "layout": "IPY_MODEL_e12a7d2aaf39458eb2a95d41007016de"
      }
     },
     "ee23e8873d2d48889c738dbbe866db9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f14b0e6139fb4a6f9d0428e67c679a60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f820722e5fbb41ebbff7770ccb3fd0f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a4dddeb7bf5048eb93542c295a4c3155",
       "style": "IPY_MODEL_f14b0e6139fb4a6f9d0428e67c679a60",
       "value": " 68785/68785 [00:04&lt;00:00, 12544.90 examples/s]"
      }
     },
     "f836bd2efe0646699d7311a0a188aa8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7461f9feddf54985afbdc18ee29b1e27",
       "style": "IPY_MODEL_da0152cf4aca4b248938c0032e9ea2ae",
       "value": "Downloading builder script: "
      }
     },
     "fa747db3ae5e49548b936c55d16e525d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fdcec9b4db554289870860096e8c5b46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_95c507c01fe843b081c55f315d904a52",
       "style": "IPY_MODEL_9d8c8f631c28465eb7539f3ba8c0428b",
       "value": "Map: 100%"
      }
     },
     "ff2de936e84b4913b9ac257218c3d804": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
